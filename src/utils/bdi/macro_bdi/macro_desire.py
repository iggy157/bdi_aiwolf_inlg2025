#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""Macro desire generation (description only, â‰¤2 sentences).
- macro_belief.yml / role_social_duties ã‚’å‚ç…§
- å‡ºåŠ›ã¯ macro_desire.description ã®ã¿ï¼ˆsummary ã¯ç”Ÿæˆã—ãªã„ï¼‰
- description ã¯æœ€å¤§ 2 æ–‡ã«åˆ¶é™
- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¯ config.yml ã® prompt.macro_desire ã‚’ä½¿ç”¨ï¼ˆã‚³ãƒ¼ãƒ‰å†…ã«åŸ‹ã‚è¾¼ã¾ãªã„ï¼‰
"""

from __future__ import annotations

import os
import re
import yaml
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, Tuple
from jinja2 import Template

# ====== ãƒ‘ã‚¹ ======
BASE = Path("/home/bi23056/lab/inlg2025/bdi_aiwolf_inlg2025")
CFG_PATH = BASE / "config" / "config.yml"

# ====== IO ======
def load_yaml_file(file_path: Path) -> Dict[str, Any]:
    if not file_path.exists():
        raise FileNotFoundError(f"File not found: {file_path}")
    with file_path.open("r", encoding="utf-8") as f:
        return yaml.safe_load(f) or {}

def _safe_mkdir(p: Path) -> None:
    p.mkdir(parents=True, exist_ok=True)

def _atomic_write_text(text: str, dst: Path) -> None:
    _safe_mkdir(dst.parent)
    tmp = dst.with_suffix(dst.suffix + ".tmp")
    with tmp.open("w", encoding="utf-8") as f:
        f.write(text)
        f.flush()
    os.replace(tmp, dst)

def _atomic_write_yaml(obj: Dict[str, Any], dst: Path) -> None:
    text = yaml.safe_dump(obj, allow_unicode=True, sort_keys=False, default_flow_style=False)
    _atomic_write_text(text, dst)

# ====== å½¹è·æ­£è¦åŒ–ï¼ˆã“ã®6ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ã¿å¯¾å¿œï¼‰ ======
# å…¥åŠ›ã«å¯¾ã—ã¦è¿”ã™è¡¨ç¤ºåï¼ˆè‹±èªã‚¿ã‚¤ãƒˆãƒ«ã‚±ãƒ¼ã‚¹ï¼‰
ROLE_NORMALIZE_TABLE = {
    "villager":  "Villager",  "Villager": "Villager",  "æ‘äºº":   "Villager",
    "seer":      "Seer",      "Seer":     "Seer",      "å ã„å¸«": "Seer",
    "werewolf":  "Werewolf",  "Werewolf": "Werewolf",  "äººç‹¼":   "Werewolf",
    "possessed": "Possessed", "Possessed":"Possessed", "ç‹‚äºº":   "Possessed",
    "bodyguard": "Bodyguard", "Bodyguard":"Bodyguard", "é¨å£«":   "Bodyguard",
    "medium":    "Medium",    "Medium":   "Medium",    "éœŠåª’å¸«": "Medium",
}
# config.role_social_duties ã§ã®ã‚­ãƒ¼å¯¾å¿œï¼ˆBodyguard ã¯ Knight é…ä¸‹ã«å®šç¾©ãŒã‚ã‚‹æƒ³å®šï¼‰
CONFIG_ROLE_KEY = {
    "Villager":  "Villager",
    "Seer":      "Seer",
    "Werewolf":  "Werewolf",
    "Possessed": "Possessed",
    "Bodyguard": "Knight",
    "Medium":    "Medium",
}

def _normalize_role_name(s: str | None) -> str:
    if not s:
        return "Villager"
    key = s.strip()
    return ROLE_NORMALIZE_TABLE.get(key, "Villager")

def _supplement_role_definition(display_role: str, role_definition: str,
                                config_data: Dict[str, Any]) -> Tuple[str, str]:
    """display_role ã‚’å‰æã«ã€config.yml ã‹ã‚‰å½¹è·å®šç¾©ã‚’è£œå®Œã—ã¦è¿”ã™ã€‚"""
    if role_definition:
        return display_role, role_definition
    rsd = (config_data.get("role_social_duties") or {}) if isinstance(config_data, dict) else {}
    cfg_key = CONFIG_ROLE_KEY.get(display_role, display_role)
    if cfg_key in rsd:
        role_definition = rsd[cfg_key].get("definition") or rsd[cfg_key].get("å®šç¾©") or role_definition
    return display_role, (role_definition or "")

# ====== ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰ï¼ˆconfig.yml ç®¡ç†ï¼‰ ======
def build_prompt(template: str, game_id: str, agent: str, role: str,
                 role_definition: str, desire_tendencies: Dict[str, float]) -> str:
    return Template(template).render(
        game_id=game_id,
        agent=agent,
        role=role,
        role_definition=role_definition,
        desire_tendencies=desire_tendencies or {},
    ).strip()

# ====== æŠ½å‡ºãƒ­ãƒã‚¹ãƒˆåŒ– ======
def _sanitize_text(s: str) -> str:
    s = (s or "").lstrip("\ufeff").strip()
    s = s.replace("â€œ", '"').replace("â€", '"').replace("â€™", "'").replace("â€¦", "...")
    s = re.sub(r"^(yaml|yml)\s*\r?\n", "", s, flags=re.IGNORECASE)
    return s

def _unfence(s: str) -> str | None:
    m = re.search(r"```(?:yaml|yml)?\s*\r?\n([\s\S]*?)\r?\n```", s, re.IGNORECASE)
    return m.group(1).strip() if m else None

def _slice_from_key(s: str, key: str = "macro_desire:") -> str | None:
    i = s.lower().find(key)
    return s[i:].strip() if i != -1 else None

def extract_yaml_from_response(response: str) -> Dict[str, Any]:
    """LLMå¿œç­”ã‹ã‚‰ YAML ã‚’é ‘å¥ã«æŠ½å‡ºï¼ˆå¤±æ•—æ™‚ã¯ description ã‚’æ•‘æ¸ˆï¼‰ã€‚"""
    s = _sanitize_text(response)
    body = _unfence(s)
    if body:
        try:
            return yaml.safe_load(body) or {}
        except yaml.YAMLError:
            pass
    try:
        return yaml.safe_load(s) or {}
    except yaml.YAMLError:
        pass
    tail = _slice_from_key(s)
    if tail:
        try:
            return yaml.safe_load(tail) or {}
        except yaml.YAMLError:
            pass
    # æœ€å¾Œã®æ‰‹æ®µï¼šdescription è¡Œã ã‘æŠ½å‡º
    m = re.search(r"description\s*:\s*(.+)", s, re.IGNORECASE)
    desc = (m.group(1).strip()) if m else "Auto-generated description."
    return {"macro_desire": {"description": desc}}

# ====== æ–‡æ•°åˆ¶å¾¡ï¼ˆæœ€å¤§2æ–‡ï¼‰ ======
def _limit_sentences(text: str, max_sents: int = 2) -> str:
    t = (text or "").strip()
    if not t:
        return t
    # æ—¥è‹±ã£ã½ã„å¥ç‚¹ã§åŒºåˆ‡ã£ã¦2æ–‡ã¾ã§
    parts = re.split(r"(?<=[ã€‚ï¼\.!?ï¼ï¼Ÿã€])\s+", t)
    parts = [p.strip() for p in parts if p.strip()]
    trimmed = " ".join(parts[:max_sents]).strip()
    return trimmed if re.search(r"[ã€‚ï¼\.!?ï¼ï¼Ÿã€]$", trimmed) else (trimmed + "." if trimmed else "")

# ====== æ­£è¦åŒ–ï¼ˆdescription ã®ã¿ï¼‰ ======
def normalize_macro_desire(data: Dict[str, Any]) -> Dict[str, Any]:
    """macro_desire.description ã‚’å¿…é ˆã«ã—ã€æœ€å¤§2æ–‡ã«åˆ¶é™ã€‚"""
    if "macro_desire" not in data or not isinstance(data["macro_desire"], dict):
        data = {"macro_desire": (data if isinstance(data, dict) else {})}
    md = data["macro_desire"]
    desc = str(md.get("description") or "")
    desc = desc.replace("```", "").strip()
    desc = re.sub(r"^yaml\s*", "", desc, flags=re.IGNORECASE)
    desc = _limit_sentences(desc, 2)
    return {"macro_desire": {"description": desc}}

# ====== æ±ºå®šè«–ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆdescription ã®ã¿ãƒ»æœ€å¤§2æ–‡ï¼‰ ======
def build_deterministic_macro_desire(agent: str, role: str,
                                     role_definition: str,
                                     desire_tendencies: Dict[str, float]) -> Dict[str, Any]:
    # ä¸Šä½2å‚¾å‘ã‚’æ–‡ã«ç¹”ã‚Šè¾¼ã‚€ï¼ˆè»½é‡ï¼‰
    tops = sorted((desire_tendencies or {}).items(), key=lambda kv: kv[1], reverse=True)[:2]
    drivers = ", ".join(k.replace("_"," ") for k,_ in tops) if tops else "stability"
    s1 = f"{agent} aims to fulfill the {role} role while prioritizing {drivers}."
    s2 = f"Role duties: {role_definition or 'n/a'}."
    return {"macro_desire": {"description": _limit_sentences(f'{s1} {s2}', 2)}}

def _is_unusable(md_obj: Dict[str, Any]) -> bool:
    d = (md_obj or {}).get("description", "")
    return len((d or "").strip()) < 10

# ====== ãƒ¡ã‚¤ãƒ³ ======
def generate_macro_desire(
    game_id: str,
    agent: str,
    agent_obj,
    dry_run: bool = False,
    overwrite: bool = False
) -> Dict[str, Any]:
    """Generate macro_desire (description only, â‰¤2 sentences) from macro_belief data."""
    mb_path = BASE / "info" / "bdi_info" / "macro_bdi" / game_id / agent / "macro_belief.yml"
    cfg_path = CFG_PATH
    out_path = BASE / "info" / "bdi_info" / "macro_bdi" / game_id / agent / "macro_desire.yml"

    if out_path.exists() and not overwrite and not dry_run:
        raise FileExistsError(f"Output file already exists: {out_path}. Use --overwrite to overwrite.")

    try:
        macro_belief_data = load_yaml_file(mb_path)
        config_data = load_yaml_file(cfg_path)
    except Exception:
        macro_belief_data, config_data = {"macro_belief": {}}, {}

    # macro_belief ã‹ã‚‰å½¹è·/å®šç¾©/å‚¾å‘
    m = macro_belief_data.get("macro_belief", {}) or {}
    role_data = m.get("role_social_duties", {}) or {}
    role_raw = role_data.get("role") or m.get("role") or "Villager"
    role_display = _normalize_role_name(role_raw)
    duties = role_data.get("duties", {}) if isinstance(role_data.get("duties", {}), dict) else {}
    role_def = duties.get("definition") or duties.get("å®šç¾©") or m.get("role_definition") or ""
    role_display, role_def = _supplement_role_definition(role_display, role_def, config_data)

    dt = m.get("desire_tendency", {}) or {}
    desire_tendencies = dt.get("desire_tendencies") or dt
    if not isinstance(desire_tendencies, dict):
        desire_tendencies = {}

    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆconfig.yml å¿…é ˆï¼‰
    prompt_template = (config_data.get("prompt", {}) or {}).get("macro_desire", "")
    if not prompt_template:
        raise RuntimeError("prompt.macro_desire is missing in config.yml")

    prompt = build_prompt(prompt_template, game_id, agent, role_display, role_def, desire_tendencies)
    if dry_run:
        print("---- PROMPT ----")
        print(prompt)

    # LLM å‘¼ã³å‡ºã—
    if agent_obj is None:
        raise ValueError("agent_obj is required. Direct API calls are not allowed.")
    extra_vars = {
        "game_id": game_id,
        "agent": agent,
        "role": role_display,
        "role_definition": role_def,
        "desire_tendencies": desire_tendencies
    }
    response = agent_obj.send_message_to_llm(
        "macro_desire",
        extra_vars=extra_vars,
        log_tag="MACRO_DESIRE_GENERATION_LITE",
        use_shared_history=False
    )
    if response is None:
        raise ValueError("Agent LLM call returned None")

    # ãƒ‘ãƒ¼ã‚¹ & æ­£è¦åŒ–ï¼ˆdescription ã®ã¿ã€æœ€å¤§2æ–‡ï¼‰
    parsed = extract_yaml_from_response(response)
    normalized = normalize_macro_desire(parsed)

    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    if _is_unusable(normalized.get("macro_desire", {})):
        normalized = build_deterministic_macro_desire(agent, role_display, role_def, desire_tendencies)

    # ãƒ¡ã‚¿ä»˜ä¸
    final_data = {
        **normalized,
        "meta": {
            "game_id": game_id,
            "agent": agent,
            "model": (agent_obj.config.get("openai", {}).get("model")
                      or agent_obj.config.get("google", {}).get("model")
                      or agent_obj.config.get("ollama", {}).get("model")),
            "generated_at": datetime.utcnow().replace(microsecond=0).isoformat() + "Z",
            "source_macro_belief": str(mb_path)
        }
    }

    if dry_run:
        print("---- RESULT ----")
        print(yaml.safe_dump(final_data, allow_unicode=True, sort_keys=False))
        return final_data

    _atomic_write_yaml(final_data, out_path)
    print(f"Saved macro_desire: {out_path}")
    return final_data

def main():
    """Deprecated CLI function."""
    print("âŒ This CLI no longer calls LLM directly.")
    print("ğŸ’¡ Run from Agent runtime context instead.")
    print("   Example: agent.generate_macro_desire(game_id, agent_name, agent_obj=agent)")
    return 1

if __name__ == "__main__":
    exit(main())
